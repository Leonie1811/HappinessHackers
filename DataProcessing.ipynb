{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheoLequy/HappinessHackers/blob/main/DataProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "gOGKpQ40D3M_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm /content/sample_data/HappinessHackers -r"
      ],
      "metadata": {
        "id": "fELLMEkA6oR4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the github repo with all the data\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/TheoLequy/HappinessHackers.git\n",
        "\n",
        "# Change to this directory\n",
        "%cd HappinessHackers/data\n",
        "\n",
        "# List the files\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9cpF37Y0Ilf",
        "outputId": "663b5ca8-d8a5-47aa-cd37-edb73e38241a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'HappinessHackers'...\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Counting objects: 100% (149/149), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 149 (delta 76), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (149/149), 4.89 MiB | 4.23 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n",
            "/content/HappinessHackers/data\n",
            "average-monthly-surface-temperature.csv\n",
            "average-precipitation-per-year.csv\n",
            "covid-excess-deaths-daily-per-100k-economist.csv\n",
            "death-rate-from-suicides-gho.csv\n",
            "death-rate-in-armed-conflicts.csv\n",
            "economic-inequality-gini-index.csv\n",
            "gdp-pcap-ppp-const2017usd.csv\n",
            "happiness-cantril-ladder.csv\n",
            "human-development-index.csv\n",
            "human-rights-index-vdem.csv\n",
            "individual-liberties-and-equality-before-the-law-index.csv\n",
            "learning-adjusted-years-of-school-lays.csv\n",
            "life-expectancy.csv\n",
            "share-deaths-air-pollution.csv\n",
            "share-of-people-who-say-that-family-is-very-important-to-them-in-life.csv\n",
            "share-of-population-urban.csv\n",
            "share-of-population-with-severe-food-insecurity.csv\n",
            "tax-revenues-as-a-share-of-gdp-unu-wider.csv\n",
            "test.py\n",
            "ti-corruption-perception-index.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for multiple years\n",
        "\n",
        "# Load the base data set\n",
        "happiness_file_path = './happiness-cantril-ladder.csv'\n",
        "data = pd.read_csv(happiness_file_path)\n",
        "data = data.drop(columns='Entity')\n",
        "data.columns = ['code', 'year', 'happiness']\n",
        "\n",
        "data_directory = './'\n",
        "file_paths = [os.path.join(data_directory, filename) for filename in os.listdir(data_directory) if filename.endswith('.csv')]\n",
        "file_paths.remove(happiness_file_path)\n",
        "\n",
        "for file_path in file_paths:\n",
        "    try:\n",
        "        if file_path == \"./gdp-pcap-ppp-const2017usd.csv\":\n",
        "          df = pd.read_csv(file_path)\n",
        "          df = df.drop(columns=['Indicator Name', 'Indicator Code', 'Unnamed: 68'])\n",
        "          id_cols = [\"Country Name\", \"Country Code\"]\n",
        "          df = pd.melt(df, id_vars=id_cols, var_name='year', value_name='GDPPC')\n",
        "          df = df.rename(columns={\"Country Name\": \"entity\", \"Country Code\": \"code\"})\n",
        "        else:\n",
        "          df = pd.read_csv(file_path)\n",
        "\n",
        "        if file_path == \"./share-of-people-who-say-that-family-is-very-important-to-them-in-life.csv\":\n",
        "          df = df.drop(columns='Continent')\n",
        "\n",
        "        if file_path == \"./covid-excess-deaths-daily-per-100k-economist.csv\":\n",
        "          df['Day'] = pd.to_datetime(df['Day']).dt.year\n",
        "          df = df.rename(columns={'Day': 'year'})\n",
        "          df = df.drop(columns=['estimated_daily_excess_deaths_ci_95_top_per_100k', 'estimated_daily_excess_deaths_ci_95_bot_per_100k'])\n",
        "\n",
        "\n",
        "        if file_path == \"./average-monthly-surface-temperature.csv\":\n",
        "          df.columns = ['entity', 'code', 'year', 'date', 'monthly temp', 'yearly temp']\n",
        "          df = df.drop(columns=['date', 'monthly temp'])\n",
        "          df = df.drop_duplicates(subset=['entity', 'code', 'year'])\n",
        "\n",
        "        # Standardize column names\n",
        "        df.columns = [col.strip().lower() for col in df.columns]\n",
        "\n",
        "        # Check if required columns are present\n",
        "        required_columns = {'code', 'year'}\n",
        "        if not required_columns.issubset(set(df.columns)):\n",
        "          print(f\"Skipping {file_path} as it lacks one or more required columns.\")\n",
        "          continue\n",
        "\n",
        "        # convert years to ints\n",
        "        df[\"year\"] = df[\"year\"].astype(int)\n",
        "\n",
        "        if 'entity' in df.columns:\n",
        "          df = df.drop(columns='entity')\n",
        "\n",
        "        # Group by 'entity' and average the values if there are duplicates\n",
        "        if df.duplicated(subset=['code', 'year']).any():\n",
        "            df = df.groupby(['code', 'year']).mean().reset_index()\n",
        "\n",
        "        data = pd.merge(data, df, on=['code', 'year'], how='left')\n",
        "\n",
        "        print(f\"Processed {file_path}: {len(df.columns)}, {df.columns}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {file_path}: {e}\")\n",
        "        continue\n",
        "\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "if not data.empty:\n",
        "    # Save the result into a new CSV file\n",
        "    output_filename = '../final_dataset_raw.csv'\n",
        "    data.to_csv(output_filename, index=False)\n",
        "\n",
        "    # Group by 'code' and calculate the average for other columns\n",
        "    data['covid'] = data['covid'].fillna(0)\n",
        "    country_avg = data.groupby('code').transform(lambda x: x.fillna(round(x.mean(),3)))\n",
        "    # Fill missing values in the original DataFrame with the calculated averages\n",
        "    data_filled = data.combine_first(country_avg)\n",
        "\n",
        "    # reorder the columns\n",
        "    data_filled = data_filled[data.columns]\n",
        "    # Save the result into a new CSV file\n",
        "    output_filename = '../final_dataset_filled.csv'\n",
        "    data_filled.to_csv(output_filename, index=False)\n",
        "    print(\"Data processing and merging complete.\")\n",
        "else:\n",
        "    print(\"No data to process.\")\n"
      ],
      "metadata": {
        "id": "5ZFkfbU79IM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d592cc-3104-4d66-93dc-5027d570f03d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed ./gdp-pcap-ppp-const2017usd.csv: 3, Index(['code', 'year', 'gdppc'], dtype='object')\n",
            "Processed ./share-of-population-urban.csv: 3, Index(['code', 'year', 'urbanization'], dtype='object')\n",
            "Processed ./ti-corruption-perception-index.csv: 3, Index(['code', 'year', 'corruption'], dtype='object')\n",
            "Processed ./share-of-population-with-severe-food-insecurity.csv: 3, Index(['code', 'year', 'food_insec'], dtype='object')\n",
            "Processed ./tax-revenues-as-a-share-of-gdp-unu-wider.csv: 3, Index(['code', 'year', 'tax'], dtype='object')\n",
            "Processed ./individual-liberties-and-equality-before-the-law-index.csv: 3, Index(['code', 'year', 'indiv_libs'], dtype='object')\n",
            "Processed ./learning-adjusted-years-of-school-lays.csv: 3, Index(['code', 'year', 'school'], dtype='object')\n",
            "Processed ./life-expectancy.csv: 3, Index(['code', 'year', 'life_expect'], dtype='object')\n",
            "Processed ./average-monthly-surface-temperature.csv: 3, Index(['code', 'year', 'yearly temp'], dtype='object')\n",
            "Processed ./human-rights-index-vdem.csv: 3, Index(['code', 'year', 'hri'], dtype='object')\n",
            "Processed ./death-rate-from-suicides-gho.csv: 3, Index(['code', 'year', 'suicides'], dtype='object')\n",
            "Processed ./share-of-people-who-say-that-family-is-very-important-to-them-in-life.csv: 3, Index(['code', 'year', 'family'], dtype='object')\n",
            "Processed ./covid-excess-deaths-daily-per-100k-economist.csv: 3, Index(['code', 'year', 'covid'], dtype='object')\n",
            "Processed ./death-rate-in-armed-conflicts.csv: 3, Index(['code', 'year', 'war'], dtype='object')\n",
            "Processed ./human-development-index.csv: 3, Index(['code', 'year', 'hdi'], dtype='object')\n",
            "Processed ./average-precipitation-per-year.csv: 3, Index(['code', 'year', 'rain'], dtype='object')\n",
            "Processed ./share-deaths-air-pollution.csv: 3, Index(['code', 'year', 'air_pollution'], dtype='object')\n",
            "Processed ./economic-inequality-gini-index.csv: 3, Index(['code', 'year', 'gini'], dtype='object')\n",
            "  code  year  happiness        gdppc  urbanization  corruption  food_insec  \\\n",
            "0  AFG  2022     1.8590          NaN           NaN         NaN         NaN   \n",
            "1  AFG  2021     2.4038  1516.273265        26.314         NaN        28.4   \n",
            "2  AFG  2020     2.5229  1968.341002        26.026         NaN        22.6   \n",
            "3  AFG  2019     2.5669  2079.921861        25.754         NaN        19.8   \n",
            "4  AFG  2018     3.2033  2060.698973        25.495        16.0        17.3   \n",
            "\n",
            "        tax  indiv_libs    school  ...  yearly temp    hri  suicides  family  \\\n",
            "0       NaN       0.015       NaN  ...    13.753037  0.038       NaN     NaN   \n",
            "1       NaN       0.137       NaN  ...    13.982875  0.175       NaN     NaN   \n",
            "2  6.760211       0.417  5.052838  ...    12.358907  0.560       NaN     NaN   \n",
            "3  8.362843       0.365       NaN  ...    12.955639  0.517      5.96     NaN   \n",
            "4  9.173828       0.381  4.949788  ...    13.735786  0.558      5.91     NaN   \n",
            "\n",
            "      covid        war    hdi   rain  air_pollution  gini  \n",
            "0  0.250676   3.642219    NaN    NaN            NaN   NaN  \n",
            "1  0.282519  90.699480  0.478    NaN            NaN   NaN  \n",
            "2  0.178229  53.391857  0.483    NaN            NaN   NaN  \n",
            "3       NaN  80.469696  0.488  327.0      16.609505   NaN  \n",
            "4       NaN  73.110790  0.483  327.0      16.527699   NaN  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "Data processing and merging complete.\n"
          ]
        }
      ]
    }
  ]
}